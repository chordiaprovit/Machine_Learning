Test with different max_iter in mlpclassifier
Train:Test = 75:25
When hidden layer size is 100*100

iters =[20, 50, 80, 100, 150, 200, 250, 280]
train_set_score =[0.7844761904761904, 0.9063809523809524, 0.9214603174603174, 0.9308571428571428, 0.9252380952380952, 0.9252380952380952, 0.9252380952380952, 0.9252380952380952]
test_set_score= [0.7846666666666666, 0.890095238095238, 0.8998095238095238, 0.9064761904761904, 0.8998095238095238, 0.8998095238095238, 0.8998095238095238, 0.8998095238095238]
train_set_loss =[1.297866771464176, 0.5091021970261552, 0.342885520563196, 0.2924443652252418, 0.2924767781831614, 0.2924767781831614, 0.2924767781831614, 0.2924767781831614]
overall_accuracy= [0.7846666666666666, 0.890095238095238, 0.8998095238095238, 0.9064761904761904, 0.8998095238095238, 0.8998095238095238, 0.8998095238095238, 0.8998095238095238]
time_taken= [6.092371940612793, 15.134122848510742, 24.088778972625732, 30.512476921081543, 31.721768856048584, 31.54016591184082, 2330.409683942795, 2024.3494350910187]


Test With different learning rates
learning_rate [0.1, 0.05, 0.01, 0.001, 0.0001]
train_set_score [0.695968253968254, 0.7690476190476191, 0.9275555555555556, 0.9744444444444444, 0.9019365079365079]
test_set_score [0.694, 0.7643809523809524, 0.9160952380952381, 0.9325714285714286, 0.882095238095238]
train_set_loss [0.9299299074501948, 0.6583960174286952, 0.2619799834094038, 0.09626442439872959, 0.5079020271349892]
overall_accuracy [0.694, 0.7643809523809524, 0.9160952380952381, 0.9325714285714286, 0.882095238095238]
time_taken [7.055665969848633, 3.304687023162842, 13.27058219909668, 123.23918199539185, 121.83721899986267]


Test with different activation functions

activation_type ['logistic', 'tanh', 'relu']
train_set_score [0.9746984126984127, 0.9456825396825397, 0.9897777777777778]
train_set_loss [0.09419514526036235, 0.19602628312514833, 0.04181046006555077]
overall_accuracy [0.9283809523809524, 0.9282857142857143, 0.9377142857142857]
time_taken [116.87999510765076, 19.00499200820923, 57.54518103599548]

Best results
Which Hidden layer size is more it performs best. 


activation='logistic',solver='sgd',hidden_layer_sizes=(100,100),
                 random_state=1,learning_rate_init=0.001,max_iter=200
train_set_score [0.9743492063492063]
train_set_loss [0.09733817115165078]
overall_accuracy [0.934]
time_taken [112.46784281730652]


activation='logistic',solver='sgd',hidden_layer_sizes=(50,50),
                 random_state=1,learning_rate_init=0.001,max_iter=200
train_set_score [0.9713650793650793]
train_set_loss [0.12275642372744267]
overall_accuracy [0.9356190476190476]
time_taken [63.088672161102295]

activation='logistic',solver='sgd',hidden_layer_sizes=(10,10),
                 random_state=1,learning_rate_init=0.001,max_iter=200
train_set_score [0.8573015873015873]
train_set_loss [0.6001955125351068]
overall_accuracy [0.8486666666666667]
time_taken [29.361776113510132]


for 100*100*100
train_set_score 0.9828571428571429
test_set_score 0.9228571428571428
loss 0.08001203322991518
time_taken [157.46578216552734]

for 50*50
train_set_score 0.9730952380952381
test_set_score 0.9323809523809524
loss 0.10215880385587044
time_taken [110.92860198020935]


Single layer(100) and multiple layer (2 layer 100*100)
iters [20, 50, 80, 100, 150, 200, 250, 300]
train_set_score [0.9454761904761905, 0.9692857142857143, 0.9784013605442177, 0.9799659863945578, 0.9822789115646259, 0.9834693877551021, 0.9834693877551021, 0.9834693877551021]
test_set_score [0.927063492063492, 0.9376190476190476, 0.9396031746031746, 0.9406349206349206, 0.9413492063492064, 0.9413492063492064, 0.9413492063492064, 0.9413492063492064]
train_set_loss [0.23216484995935419, 0.13112868331091504, 0.09272599111071278, 0.08249948342581029, 0.07071613244063475, 0.06465028058162554, 0.06465028058162554, 0.06465028058162554]
overall_accuracy [0.927063492063492, 0.9376190476190476, 0.9396031746031746, 0.9406349206349206, 0.9413492063492064, 0.9413492063492064, 0.9413492063492064, 0.9413492063492064]
train_set_score_multi [0.8992517006802722, 0.9458843537414966, 0.959047619047619, 0.9650680272108844, 0.9703741496598639, 0.9722108843537415, 0.9722108843537415, 0.9722108843537415]
test_set_score_multi [0.8929365079365079, 0.921031746031746, 0.9273809523809524, 0.9297619047619048, 0.9312698412698412, 0.9324603174603174, 0.9324603174603174, 0.9324603174603174]
train_set_loss_multi [0.5637825400190819, 0.24250667012857413, 0.1675363788706298, 0.14078587707471252, 0.11303260343681269, 0.10397092359217534, 0.10397092359217534, 0.10397092359217534]
overall_accuracy_multi [0.8929365079365079, 0.921031746031746, 0.9273809523809524, 0.9297619047619048, 0.9312698412698412, 0.9324603174603174, 0.9324603174603174, 0.9324603174603174]
time_taken [11.723015785217285, 28.970237970352173, 46.601343870162964, 57.993858098983765, 3013.897710800171, 120.37677597999573, 13692.604579925537, 116.91032910346